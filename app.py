from uuid import uuid4

import gradio as gr

from src.assistant import Assistant


assistant = Assistant(service_cfg_path="configs/deployment_config.yaml")


def _build_index_request(repo_url: str) -> tuple[dict, dict]:
    request = {
        "meta": {"request_id": str(uuid4())},
        "repo_url": repo_url,
        "branch": "main",
    }

    config = {
        "ast_chunker_config": {
            "max_chunk_size": 1000,
            "chunk_overlap": 50,
            "extensions": [
                ".py",
                ".ipynb",
                ".cpp",
                ".h",
                ".java",
                ".ts",
                ".tsx",
                ".cs",
            ],
            "chunk_expansion": True,
            "metadata_template": "default",
        },
        "text_splitter_config": {"chunk_size": 500, "chunk_overlap": 50},
        "exclude_patterns": ["*.lock", "__pycache__", ".venv", "build"],
    }

    return request, config


def _build_search_config() -> dict:
    return {
        "query_preprocessor": {
            "enabled": True,
            "normalize_whitespace": True,
            "sanitization": {
                "enabled": True,
                "regex_patterns": ["jailbreak", "hallucinations"],
                "replacement_token": "",
            },
        },
        "query_rewriter": {"enabled": False},
        "retriever": {"enabled": True},
        "filtering": {"enabled": True},
        "reranker": {"enabled": False},
        "context_expansion": {"enabled": True},
        "qa": {"enabled": True},
        "query_postprocessor": {
            "enabled": True,
            "format_markdown": True,
            "sanitization": {
                "enabled": True,
                "regex_patterns": ["can't", "wtf"],
                "replacement_token": "",
            },
        },
    }


async def index_repo(repo_url: str) -> str:
    if not repo_url:
        return "âŒ **ĞÑˆĞ¸Ğ±ĞºĞ°:** Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ GitHub URL."

    request, config = _build_index_request(repo_url)
    
    try:
        response = await assistant.index(request, config)
        
        # Calculate duration
        duration = (response.meta.end_datetime - response.meta.start_datetime).total_seconds()
        
        # Build verbose response
        result = []
        result.append("## ğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ğ¸\n")
        result.append(f"**Request ID:** `{response.meta.request_id}`\n")
        result.append(f"**Repository URL:** {response.repo_url}\n")
        result.append(f"**Ğ’Ñ€ĞµĞ¼Ñ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ñ:** {duration:.2f} ÑĞµĞºÑƒĞ½Ğ´\n")
        result.append(f"**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:** {response.meta.status}\n")
        
        # Check if repo was already indexed
        is_already_indexed = (response.job_status.description_error and 
                             "already indexed" in response.job_status.description_error.lower())
        
        if is_already_indexed:
            result.append("\nâš ï¸ **Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ ÑƒĞ¶Ğµ Ğ¿Ñ€Ğ¾Ğ¸Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½**\n")
            result.append("Ğ˜Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ñ Ğ±Ñ‹Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ°, Ñ‚Ğ°Ğº ĞºĞ°Ğº Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ ÑƒĞ¶Ğµ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒĞµÑ‚ Ğ² Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….\n")
        else:
            # Show job status details
            if response.job_status.status:
                status_emoji = {
                    "failed": "âŒ",
                    "loaded": "ğŸ“¥",
                    "parsed": "ğŸ”",
                    "vectorized": "ğŸ§®",
                    "saved_to_qdrant": "âœ…"
                }
                emoji = status_emoji.get(response.job_status.status, "â„¹ï¸")
                result.append(f"\n**Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸:** {emoji} {response.job_status.status}\n")
            
            # Show chunks processed
            if response.job_status.chunks_processed is not None:
                result.append(f"**ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²:** {response.job_status.chunks_processed}\n")
            
            # Show errors if any
            if response.meta.status == "error":
                result.append("\n### âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ğ¸\n")
                if response.job_status.description_error:
                    result.append(f"**ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸:**\n```\n{response.job_status.description_error}\n```\n")
                else:
                    result.append("ĞŸÑ€Ğ¾Ğ¸Ğ·Ğ¾ÑˆĞ»Ğ° Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ğ¸.\n")
            elif response.job_status.status == "saved_to_qdrant":
                result.append("\n### âœ… Ğ˜Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾\n")
                result.append("Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ¸Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½ Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ±Ğ°Ğ·Ñƒ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ….\n")
        
        return "".join(result)
        
    except Exception as e:
        return f"âŒ **ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°:** {type(e).__name__}: {str(e)}"


def _collect_sources(response) -> list[dict]:
    sources = []
    if getattr(response, "sources", None):
        for source in response.sources:
            sources.append(
                {
                    "filepath": source.metadata.filepath,
                    "language": source.metadata.language or "",
                    "content": source.content,
                }
            )
    return sources


def _render_sources(sources: list[dict], show_sources: bool) -> str:
    if not sources:
        return "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:\n- Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾\n"

    sources_md = "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:\n"
    for source in sources:
        sources_md += f"- {source['filepath']}\n"
        if show_sources:
            sources_md += f"\n```{source['language']}\n"
            sources_md += f"{source['content']}\n"
            sources_md += "```\n"
    return sources_md


def _content_to_text(content) -> str:
    if content is None:
        return ""
    if isinstance(content, str):
        return content
    if isinstance(content, dict):
        return str(content.get("text") or content.get("content") or "")
    if isinstance(content, list):
        parts = []
        for item in content:
            if isinstance(item, str):
                parts.append(item)
            elif isinstance(item, dict):
                if item.get("type") == "text":
                    parts.append(str(item.get("text", "")))
                elif "text" in item:
                    parts.append(str(item.get("text", "")))
        return "".join(parts)
    return str(content)


def _normalize_history(history: list[dict] | None) -> list[dict]:
    """Ensure history is list of {'role': str, 'content': str}."""
    if not history:
        return []
    out = []
    for m in history:
        if isinstance(m, dict) and "role" in m:
            out.append({"role": str(m.get("role", "")), "content": _content_to_text(m.get("content"))})
    return out


def _last_pairs(history: list[dict], pairs: int = 3) -> list[dict]:
    """Keep last N user+assistant pairs = 2*N messages."""
    max_msgs = 2 * pairs
    return history if len(history) <= max_msgs else history[-max_msgs:]


async def chat(
    repo_url: str,
    message: str,
    show_sources: bool,
    history_state: list[dict],
    chatbot_history: list[dict],
):
    history_state = _normalize_history(history_state)
    chatbot_history = _normalize_history(chatbot_history)

    if not repo_url:
        return "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ URL Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ.", "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:\n- Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾\n", [], history_state, chatbot_history

    if not message:
        return "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ.", "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:\n- Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾\n", [], history_state, chatbot_history

    # Backend context: last 3 Q/A pairs (6 msgs) + new question
    context_messages = _last_pairs(history_state, pairs=3)
    request_messages = context_messages + [{"role": "user", "content": message}]

    request = {
        "meta": {"request_id": str(uuid4())},
        "query": {"messages": request_messages},
        "repo_url": repo_url,
    }
    config = _build_search_config()

    try:
        response = await assistant.query(request, config)
        answer_text = (getattr(response, "answer", "") or "").strip()
    except Exception as e:
        return f"ĞÑˆĞ¸Ğ±ĞºĞ°: {type(e).__name__}: {e}", "Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:\n- Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾\n", [], history_state, chatbot_history

    final_answer = answer_text or "ĞÑ‚Ğ²ĞµÑ‚ Ğ¿ÑƒÑÑ‚."

    sources = _collect_sources(response)
    sources_md = _render_sources(sources, show_sources)

    chatbot_history = chatbot_history + [
        {"role": "user", "content": message},
        {"role": "assistant", "content": final_answer},
    ]

    new_history_state = request_messages + [{"role": "assistant", "content": final_answer}]
    new_history_state = _last_pairs(new_history_state, pairs=3)

    return sources_md, sources, new_history_state, chatbot_history


def update_sources(show_sources: bool, sources: list[dict]):
    return _render_sources(sources or [], show_sources)


with gr.Blocks(title="RAGCode") as demo:
    gr.Markdown("# RAGCode")

    with gr.Tabs():
        with gr.Tab("Ğ˜Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹"):
            repo_url_input = gr.Textbox(label="GitHub URL")
            index_button = gr.Button("Ğ˜Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ")
            index_status = gr.Markdown()
            index_button.click(index_repo, inputs=repo_url_input, outputs=index_status)

        with gr.Tab("Ğ§Ğ°Ñ‚ Ğ¿Ğ¾ ĞºĞ¾Ğ´Ñƒ"):
            chat_repo_url = gr.Textbox(label="URL Ñ€ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ")

            chatbot = gr.Chatbot(label="Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ", height=420)

            sources = gr.Markdown("Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸:\n- Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾\n")
            message_input = gr.Textbox(label="Ğ’Ğ°Ñˆ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ")
            show_sources = gr.Checkbox(label="ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ğ¼Ğ¾Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ²", value=False)

            sources_state = gr.State([])
            history_state = gr.State([])

            send_button = gr.Button("Ğ¡Ğ¿Ñ€Ğ¾ÑĞ¸Ñ‚ÑŒ")

            send_button.click(
                chat,
                inputs=[chat_repo_url, message_input, show_sources, history_state, chatbot],
                outputs=[sources, sources_state, history_state, chatbot],
            )

            show_sources.change(
                update_sources,
                inputs=[show_sources, sources_state],
                outputs=[sources],
            )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=8501)
